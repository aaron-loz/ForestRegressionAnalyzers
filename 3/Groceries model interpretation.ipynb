{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fastai.imports import *\n",
    "#from fastai.structured import *\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import forest\n",
    "from IPython.display import display\n",
    "import re\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holidays_events.csv\n",
      "items.csv\n",
      "oil.csv\n",
      "sample_submission.csv\n",
      "test.csv\n",
      "train.csv\n",
      "transactions.csv\n"
     ]
    }
   ],
   "source": [
    "PATH = \"../2/data/groceries/\"\n",
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Reading Data\n",
    "## to ensure a header is assigned the correct datatypes, define the dictionary you want it to be mapped to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {'id': 'int64',\n",
    "        'item_nbr': 'int32',\n",
    "        'store_nbr': 'int8',\n",
    "        'unit_sales': 'float32',\n",
    "        'onpromotion': 'object'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_all = pd.read_csv(f'{PATH}train.csv', parse_dates = ['date'], dtype = types,\n",
    "                    infer_datetime_format = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in practice, you don't need to read the whole thing in. use the linux command 'shuf'. This will parse a sample and the sample is what you use to work with instead of waiting for the entire data to come in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will fill in missing values with false, since we know that there is na in the 'onpromotion' section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['onpromotion'].fillna(False, inplace = True)# changes all NaN entries to False, and keeps anything that is an entry.\n",
    "df_all['onpromotion'] = df_all['onpromotion'].map({'False' : False, 'True': True})#maps the entry 'False' to boolean False\n",
    "df_all['onpromotion'] = df_all['onpromotion'].astype(bool)#changes the dtype to boolean for the entire column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.46 s\n"
     ]
    }
   ],
   "source": [
    "%time df_all.to_feather('tmp/raw_groceries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.254970e+08</td>\n",
       "      <td>125497040</td>\n",
       "      <td>1.254970e+08</td>\n",
       "      <td>1.254970e+08</td>\n",
       "      <td>1.254970e+08</td>\n",
       "      <td>125497040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>118194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96028767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-15 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.274852e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.746458e+01</td>\n",
       "      <td>9.727692e+05</td>\n",
       "      <td>5.319669e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.622788e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.633051e+01</td>\n",
       "      <td>5.205336e+05</td>\n",
       "      <td>2.306714e+01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.699500e+04</td>\n",
       "      <td>-1.537200e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.137426e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>5.223830e+05</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.274852e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>9.595000e+05</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.412278e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.300000e+01</td>\n",
       "      <td>1.354380e+06</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.254970e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>2.127114e+06</td>\n",
       "      <td>8.944000e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                 date     store_nbr      item_nbr  \\\n",
       "count   1.254970e+08            125497040  1.254970e+08  1.254970e+08   \n",
       "unique           NaN                 1684           NaN           NaN   \n",
       "top              NaN  2017-07-01 00:00:00           NaN           NaN   \n",
       "freq             NaN               118194           NaN           NaN   \n",
       "first            NaN  2013-01-01 00:00:00           NaN           NaN   \n",
       "last             NaN  2017-08-15 00:00:00           NaN           NaN   \n",
       "mean    6.274852e+07                  NaN  2.746458e+01  9.727692e+05   \n",
       "std     3.622788e+07                  NaN  1.633051e+01  5.205336e+05   \n",
       "min     0.000000e+00                  NaN  1.000000e+00  9.699500e+04   \n",
       "25%     3.137426e+07                  NaN  1.200000e+01  5.223830e+05   \n",
       "50%     6.274852e+07                  NaN  2.800000e+01  9.595000e+05   \n",
       "75%     9.412278e+07                  NaN  4.300000e+01  1.354380e+06   \n",
       "max     1.254970e+08                  NaN  5.400000e+01  2.127114e+06   \n",
       "\n",
       "          unit_sales onpromotion  \n",
       "count   1.254970e+08   125497040  \n",
       "unique           NaN           2  \n",
       "top              NaN       False  \n",
       "freq             NaN    96028767  \n",
       "first            NaN         NaN  \n",
       "last             NaN         NaN  \n",
       "mean    5.319669e+00         NaN  \n",
       "std     2.306714e+01         NaN  \n",
       "min    -1.537200e+04         NaN  \n",
       "25%     2.000000e+00         NaN  \n",
       "50%     4.000000e+00         NaN  \n",
       "75%     9.000000e+00         NaN  \n",
       "max     8.944000e+04         NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df_all.describe(include = 'all')# the param 'include' allows describing EVERYTHING. Useful for stats items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.370464e+06</td>\n",
       "      <td>3370464</td>\n",
       "      <td>3.370464e+06</td>\n",
       "      <td>3.370464e+06</td>\n",
       "      <td>3370464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-27 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>210654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3171867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-16 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.271823e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.750000e+01</td>\n",
       "      <td>1.244798e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.729693e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.558579e+01</td>\n",
       "      <td>5.898362e+05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.254970e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.699500e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.263397e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>8.053210e+05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.271823e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.750000e+01</td>\n",
       "      <td>1.294665e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.280249e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.100000e+01</td>\n",
       "      <td>1.730015e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.288675e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>2.134244e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                 date     store_nbr      item_nbr  \\\n",
       "count   3.370464e+06              3370464  3.370464e+06  3.370464e+06   \n",
       "unique           NaN                   16           NaN           NaN   \n",
       "top              NaN  2017-08-27 00:00:00           NaN           NaN   \n",
       "freq             NaN               210654           NaN           NaN   \n",
       "first            NaN  2017-08-16 00:00:00           NaN           NaN   \n",
       "last             NaN  2017-08-31 00:00:00           NaN           NaN   \n",
       "mean    1.271823e+08                  NaN  2.750000e+01  1.244798e+06   \n",
       "std     9.729693e+05                  NaN  1.558579e+01  5.898362e+05   \n",
       "min     1.254970e+08                  NaN  1.000000e+00  9.699500e+04   \n",
       "25%     1.263397e+08                  NaN  1.400000e+01  8.053210e+05   \n",
       "50%     1.271823e+08                  NaN  2.750000e+01  1.294665e+06   \n",
       "75%     1.280249e+08                  NaN  4.100000e+01  1.730015e+06   \n",
       "max     1.288675e+08                  NaN  5.400000e+01  2.134244e+06   \n",
       "\n",
       "       onpromotion  \n",
       "count      3370464  \n",
       "unique           2  \n",
       "top          False  \n",
       "freq       3171867  \n",
       "first          NaN  \n",
       "last           NaN  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(f'{PATH}test.csv', parse_dates = ['date'], dtype = types,\n",
    "                     infer_datetime_format = True)\n",
    "df_test['onpromotion'].fillna(False, inplace = True)\n",
    "df_test['onpromotion'] = df_test['onpromotion'].map({'False': False, 'True': True})\n",
    "df_test['onpromotion'] = df_test['onpromotion'].astype(bool)\n",
    "df_test.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that the data has been analyzed, we understand we have 4 years of training data to test on 2 weeks of data.\n",
    "### Now what to infer from this?\n",
    "### We should grab the most recent since data from 2013 is not as relevant. That doesn't mean it's not relevant, but it will be weighted much less. For the base case, we should focus only on the most recent,then narrow down to the most important peices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125497035</th>\n",
       "      <td>125497035</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>54</td>\n",
       "      <td>2089339</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125497036</th>\n",
       "      <td>125497036</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>54</td>\n",
       "      <td>2106464</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125497037</th>\n",
       "      <td>125497037</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>54</td>\n",
       "      <td>2110456</td>\n",
       "      <td>192.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125497038</th>\n",
       "      <td>125497038</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>54</td>\n",
       "      <td>2113914</td>\n",
       "      <td>198.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125497039</th>\n",
       "      <td>125497039</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>54</td>\n",
       "      <td>2116416</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id       date  store_nbr  item_nbr  unit_sales  onpromotion\n",
       "125497035  125497035 2017-08-15         54   2089339         4.0        False\n",
       "125497036  125497036 2017-08-15         54   2106464         1.0         True\n",
       "125497037  125497037 2017-08-15         54   2110456       192.0        False\n",
       "125497038  125497038 2017-08-15         54   2113914       198.0         True\n",
       "125497039  125497039 2017-08-15         54   2116416         2.0        False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_feather() got an unexpected keyword argument 'nthreads'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-472ffb23d45b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_feather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tmp/raw_groceries'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\feather_format.py\u001b[0m in \u001b[0;36mread_feather\u001b[1;34m(path, nthreads)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfeather\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeather\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthreads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnthreads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: read_feather() got an unexpected keyword argument 'nthreads'"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_feather('tmp/raw_groceries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['unit_sales'] = np.log1p(np.clip(df_all['unit_sales'], 0, None))#the evaluation is RMSL+1E, since log(0) is not real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The competition says to count negatives in unit sales as 0, which is what np.cllip allows us to do, we set the minimum as 0, and put None as the maximum since there is no ceiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datepart(df, fldname):\n",
    "    fld= df[fldname] \n",
    "    #not df.fldname, that would just grab a field that states 'fldname'. also safer and should do more than this.\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)#regex removes 'date' from fldname\n",
    "    for n in ('Year', 'Month', 'Week', 'Day', 'Dayofweek','Dayofyear',#goes through each string\n",
    "              'Is_month_end','Is_month_start', 'Is_quarter_end', 'Is_year_end', 'Is_year_start'):\n",
    "        df[targ_pre+n] = getattr(fld.dt,n.lower())\n",
    "        #tries to find an attribute with the same name inside each object(like Year attr)\n",
    "    df[targ_pre+'Elapsed'] = (fld - fld.min()).dt.days\n",
    "    df.drop(fldname, axis=1, inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%time add_datepart(df_all, 'date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no need for train_cats because everything is numeric already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(df, col, name, max_n_cat):\n",
    "    if not is_numeric_dtype(col) and (max_n_cat is None or col.nunique()>max_n_cat):\n",
    "        df[name] = col.cat.codes+1# if it isn't numeric, we replace with its codes.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing(df, col, name):\n",
    "    if is_numeric_dtype(col):\n",
    "        if pd.isnull(col).sum():\n",
    "            df[name+'_na'] = pd.isnull(col)\n",
    "        df[name] = col.fillna(col.median())# replaced with median, and replaces with new column telling what's missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_df(df, y_fld, skip_flds =None, do_scale = False,\n",
    "           preproc_fn = None, max_n_cat = None, subset = None):\n",
    "    if not skip_flds:#copies df, grabs y values, drops the original, and then does fix_missing\n",
    "        skip_flds = []\n",
    "    if subset:\n",
    "        df= get_sample(df, subset)\n",
    "    df = df.copy()\n",
    "    if preproc_fn:\n",
    "        preproc_fn(df)\n",
    "    y = df[y_fld].values\n",
    "    df.drop(skip_flds+[y_fld], axis=1, inplace =True)\n",
    "    \n",
    "    for n, c in df.items():\n",
    "        fix_missing(df, c, n)\n",
    "    if do_scale:\n",
    "        mapper = scale_vars(df)\n",
    "    for n, c in df.items():\n",
    "        numericalize(df, c, n, max_n_cat)\n",
    "    res = [pd.get_dummies(df, dummy_na = True), y]#discuss later\n",
    "    if not do_scale: return res\n",
    "    return res + [mapper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_vals(a, n):\n",
    "    return a[:n].copy(), a[n: ].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((122126576, 17), (3370464, 17))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_valid = len(df_test)\n",
    "n_trn = len(df_all)- n_valid\n",
    "train, valid = split_vals(df_all, n_trn)\n",
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If I needed to run train_cats:\n",
    "#train_cats(raw_train)\n",
    "#apply_cats(raw_valid, raw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trn, y = proc_df(train, 'unit_sales')\n",
    "val, y_val = proc_df(valid, 'unit_sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x,y):\n",
    "    return math.sqrt(((x-y)**2).mean())\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(X_train), Y_train), rmse(m.predict(X_valid), Y_valid),\n",
    "          m.score(X_train, Y_train), m.score(X_valid, Y_valid)]\n",
    "    if hasattr(m, 'oob_score_'):\n",
    "        res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_rf_samples(n):\n",
    "    \"\"\" Changes Scikit learn's random forests to give each tree a random sample of\n",
    "    n random rows.\n",
    "    \"\"\"\n",
    "    forest._generate_sample_indices = (lambda rs, n_samples:\n",
    "        forest.check_random_state(rs).randint(0, n_samples, n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "set_rf_samples(1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instead, the trees are created from 1 million random pieces of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1605\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1606\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1608\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.values_from_object\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mget_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4686\u001b[0m                [nan,  3.]])\n\u001b[0;32m   4687\u001b[0m         \"\"\"\n\u001b[1;32m-> 4688\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_dtype_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mvalues\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4631\u001b[0m         \"\"\"\n\u001b[0;32m   4632\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4633\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4635\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mas_array\u001b[1;34m(self, transpose, items)\u001b[0m\n\u001b[0;32m   3947\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3948\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3949\u001b[1;33m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3951\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtranspose\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_interleave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3976\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3977\u001b[0m             \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3978\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3979\u001b[0m             \u001b[0mitemmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget_values\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m    218\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time x = np.array(trn, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators = 20, min_samples_leaf=100, n_jobs = -1)\n",
    "%time m.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
